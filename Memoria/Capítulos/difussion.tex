\section{Colorización con modelos de difusión}

Los modelos de difusión se han consolidado como una de las técnicas más potentes en generación de imágenes. Su principio básico consiste en transformar ruido gaussiano en datos estructurados mediante un proceso iterativo de denoising. Formalmente, el proceso directo añade ruido a una imagen $x_0$ siguiendo una cadena de Markov:



\[
q(x_t \mid x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} \, x_{t-1}, \beta_t I),
\]



donde $\beta_t$ controla la cantidad de ruido en el paso $t$. El modelo aprende la distribución inversa $p_\theta(x_{t-1} \mid x_t)$ para recuperar la señal original. Tras suficientes iteraciones, se obtiene una imagen coherente a partir de ruido inicial. Estos métodos han demostrado gran capacidad en tareas de síntesis y edición de imágenes \cite{Zabari2023Diffusing}.  
En el contexto de la colorización, los modelos de difusión resultan útiles porque permiten generar detalles cromáticos plausibles a partir de información parcial (imágenes en escala de grises), preservando bordes y texturas.

\subsection{Arquitectura}

Nuestro modelo se basa en el \textit{VAE} de \textit{Stable Diffusion 1.5} como codificador–decodificador, sobre el cual se han probado distintas variantes de la arquitectura \texttt{UNet}:

\begin{itemize}
    \item Entrenamiento de un \texttt{UNet} desde cero.
    \item \textit{Fine-tuning} del \texttt{UNet} original de \textit{Stable Diffusion}, restringido únicamente al último bloque.
    \item Adaptación mediante \texttt{LoRA} sobre el \texttt{UNet} de \textit{Stable Diffusion}.
\end{itemize}

El entrenamiento se ha realizado con 25\,000 imágenes del dataset \texttt{STL-10}. Al tratarse de imágenes pequeñas (96$\times$96 píxeles), esto limita la capacidad del modelo para aprender detalles finos y puede afectar la nitidez cromática.  
Dado que el proceso es muy lento, se calcularon previamente las representaciones latentes con el \textit{VAE}, entrenando directamente sobre ellas para reducir el coste computacional.

\subsection{Función de pérdida}

La función de pérdida combina dos términos principales:

\begin{itemize}
    \item \textbf{Pérdida de reconstrucción}: error entre la imagen colorizada y la referencia.
    \item \textbf{Pérdida de difusión}: error de predicción del ruido en cada paso de denoising.
\end{itemize}

La combinación de ambas permite que el modelo aprenda tanto a reconstruir colores plausibles como a mantener la coherencia estructural de la imagen.

\subsection{Entrenamiento}

El entrenamiento se llevó a cabo sobre las latentes del \textit{VAE}, utilizando Adam como optimizador.  
Se exploraron diferentes configuraciones de número de pasos de difusión, observando que este parámetro no resulta crítico en la calidad final.  
El fine-tuning del \texttt{UNet} se limitó al último bloque para reducir el coste y evitar sobreajuste, mientras que la variante LoRA permitió adaptar el modelo con menor número de parámetros entrenables.

\subsection{Resultados preliminares}

Los resultados muestran limitaciones claras:

\begin{itemize}
    \item El modelo tiende a difuminar el texto presente en las imágenes.
    \item Las colorizaciones presentan regiones con aspecto grisáceo o, en ocasiones, fogonazos de color incoherentes.
    \item El rendimiento global no alcanza niveles excelentes, aunque se observan diferencias entre las variantes de \texttt{UNet}.
    \item El número de pasos de difusión no resulta determinante en la calidad final.
\end{itemize}

Para la evaluación cuantitativa se emplearán las métricas \texttt{LPIPS} y \texttt{MSE}, cuyos valores aún no han sido calculados.

\begin{table}[h]
\centering
\caption{Resultados cuantitativos preliminares de colorización con modelos de difusión (valores pendientes de cálculo).}
\label{tab:diffusion_resultados}
\begin{tabular}{lcc}
\hline
\textbf{Modelo} & \textbf{LPIPS} & \textbf{MSE} \\
\hline
UNet desde cero & -- & -- \\
Fine-tuning último bloque & -- & -- \\
LoRA sobre Stable Diffusion & -- & -- \\
\hline
\end{tabular}
\end{table}
