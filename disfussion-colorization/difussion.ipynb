{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# -------- Model stubs (replace with actual implementations / loaded weights) --------\n",
    "class SDVAE(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def encode(self, x): \n",
    "        # x: [B,3,H,W] in [-1,1]\n",
    "        # return latent z: [B,C,H',W']\n",
    "        raise NotImplementedError\n",
    "    def decode(self, z):\n",
    "        # z: [B,C,H',W']\n",
    "        # return img: [B,3,H,W] in [-1,1]\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SDUNet(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, z_t, t_emb):\n",
    "        # Predict color residual at timestep t\n",
    "        raise NotImplementedError\n",
    "\n",
    "# -------- Utilities --------\n",
    "def preprocess_gray(img_gray_pil, size=512):\n",
    "    img = img_gray_pil.resize((size, size), Image.BICUBIC)\n",
    "    arr = np.array(img).astype(np.float32) / 255.0\n",
    "    arr = (arr - 0.5) / 0.5\n",
    "    # replicate to 3 channels to feed VAE encoder\n",
    "    return torch.from_numpy(arr)[None, ...].repeat(3, 1, 1)  # [3,H,W]\n",
    "\n",
    "def timestep_embedding(t, dim=128, device='cpu'):\n",
    "    # Simple sinusoidal embedding for scalar t in [0,1]\n",
    "    # t: [B]\n",
    "    freq = torch.linspace(1.0, 1000.0, dim//2, device=device)\n",
    "    angles = t[:, None] * freq[None, :]\n",
    "    emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1)\n",
    "    return emb\n",
    "\n",
    "def replace_luma(out_rgb_norm, in_gray_norm):\n",
    "    # out_rgb_norm: [3,H,W] in [-1,1]\n",
    "    # in_gray_norm: [3,H,W] replicated gray in [-1,1]\n",
    "    out = out_rgb_norm.permute(1,2,0).cpu().numpy()*0.5+0.5  # [H,W,3] in [0,1]\n",
    "    gray = in_gray_norm[0].cpu().numpy()*0.5+0.5             # [H,W] in [0,1]\n",
    "    import cv2\n",
    "    out_bgr = cv2.cvtColor((out*255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "    lab = cv2.cvtColor(out_bgr, cv2.COLOR_BGR2Lab)\n",
    "    lab[:,:,0] = (gray*255).astype(np.uint8)  # replace L\n",
    "    bgr = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(rgb)\n",
    "\n",
    "# -------- Inference pipeline (no text) --------\n",
    "class Colorizer:\n",
    "    def __init__(self, vae: SDVAE, unet: SDUNet, device='cuda'):\n",
    "        self.vae = vae.eval().to(device)\n",
    "        self.unet = unet.eval().to(device)\n",
    "        self.device = device\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def colorize(self, gray_img_pil: Image.Image, steps=50, size=512, color_scale=1.0):\n",
    "        # 1) Preprocess and encode grayscale\n",
    "        gray = preprocess_gray(gray_img_pil, size).unsqueeze(0).to(self.device)  # [1,3,H,W]\n",
    "        z_gray = self.vae.encode(gray)  # [1,C,h,w]\n",
    "\n",
    "        # 2) Iterative cold-diffusion refinement (no text)\n",
    "        ts = torch.linspace(1.0, 0.0, steps, device=self.device)\n",
    "        z_t = z_gray.clone()\n",
    "\n",
    "        for t in ts:\n",
    "            t_emb = timestep_embedding(t[None], device=self.device)  # [1,D]\n",
    "            delta_t = self.unet(z_t, t_emb)                          # [1,C,h,w]\n",
    "            z_t = z_t + (1.0/steps) * delta_t\n",
    "\n",
    "        # 3) Apply global color scale for saturation control and decode\n",
    "        z_col = z_gray + color_scale * (z_t - z_gray)\n",
    "        out_rgb = self.vae.decode(z_col).squeeze(0)  # [3,H,W] in [-1,1]\n",
    "\n",
    "        # 4) Luma replacement to reduce artifacts\n",
    "        final_img = replace_luma(out_rgb, gray.squeeze(0))\n",
    "        return final_img\n",
    "\n",
    "# -------- Usage example --------\n",
    "# vae = load_sd15_vae()       # implement loading\n",
    "# unet = load_finetuned_unet()# implement loading (trained for color residuals)\n",
    "# colorizer = Colorizer(vae, unet, device='cuda')\n",
    "# gray = Image.open('input_grayscale.png').convert('L')\n",
    "# colorized = colorizer.colorize(gray, steps=50, size=512, color_scale=1.0)\n",
    "# colorized.save('colorized.png')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
