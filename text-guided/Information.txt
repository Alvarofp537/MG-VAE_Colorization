considering using CLIP model for text-guided colorization. 
As the model sould have more information the content of the image colorized

METHOD:
Usar text embedder preentrenado para entender las captions generadas por los modelos


MODELOS GUIDANCE:
Image Captioning: BLIP-2, Florence-2 o CLIP Interrogator para generar el prompt y no encontrar uno similar como CLIP
BLIP-2 (de Salesforce) parece el mejor
Vila (NVIDIA)model: https://github.com/NVIDIA/image-captioner

DATASETS:
IMG_TEXT data:  https://cocodataset.org/ 
Imagenes solo: ImageNet



Referencias:
generating captions: youtube.com/watch?v=2OtZJLet8u8&vl=es